# csci166

## Videos

<p>Early Video<p>



https://github.com/user-attachments/assets/c80bf5ef-de03-486d-8a40-49ae1a89a0f3




<p>Later Video<p>





https://github.com/user-attachments/assets/3ceb2735-6ecd-45ac-a743-772288417eca

## Words
<p>I chose Boxing because it looked visually intresting. Early training showed nearly random movement with the agent losing badly, while later training demonstrated improved positioning and punch timing, showing the agent learned to get a higher reward. The main challenge was sparse rewards since points only come from successful hits, making it hard for the agent to discover winning strategies during early exploration. Later on I would increase the replay buffer size and slow down epsilon decay to allow more exploration time, since the agent would benefit from more game states and data.</p>
